{
 "metadata": {
  "name": "",
  "signature": "sha256:7119cdc9ef36205c5e7e000cf648dc114a76f4108eaddc75ece9e05dd0317340"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Final Project - Pseudocode and Unit tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Here we describe the basic algorithmic steps for CLIME (constrained $\\mathcal{l}_1$-minimization for inverse matrix estimation) and CAPME (covariate-adjusted precision matrix estimation). For the solution to linear programming problem that defines precision matrix estimation, we consider the parametric simplex method and the primal-dual interior point method.\n",
      "\n",
      "First we define notation of matrix norms used in the code. For a vector $\\textbf{a}=(a_1,...,a_p)^T$, define $|\\textbf{a}|_1=\\sum_{i=1}^{p}|a_i|$ and $|\\textbf{a}|_2=\\sqrt{\\sum_{i=1}^{p}a_i^2}$. For a matrix $A=(a_{ij})\\in\\mathbb{R}^{pxq}$, define the entrywise $\\mathcal{l}_1$ norm $\\|A\\|_1=\\sum_{i=1}^{p}\\sum_{j=1}^{q}|a_{ij}|$ and the entrywise $\\mathcal{l}_\\infty$ norm $\\|A\\|_\\infty=\\max_{1\\le i\\le p,1\\le j\\le q}|a_{ij}|$. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##CLIME "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let $\\textbf{x}=(x_1,...,x_n)\\in\\mathbb{R}^{nxp}$ be $n$ observations of a $p$-dimensional random vector $\\textbf{X}=(X_1,...,X_p)^T$. For the $n\\times p$ data matrix, $\\textbf{x}$, or the $p\\times p$ sample covariance matrix, $\\Sigma_n=\\frac{1}{n}\\sum_{k=1}^{n}(x_k-\\bar{x})(x_k-\\bar{x})^T$, the CLIME method solves the following optimization problem:\n",
      "\n",
      "\\begin{equation*}\n",
      "\\hat{\\Omega}=\\arg_\\Omega\\min \\| \\mathbf{\\Omega} \\|_1\\text{ subject to }\\|\\mathbf{\\Sigma}_n\\mathbf{\\Omega}-\\textbf{I}\\|_\\infty\\le\\lambda_n\\text{, }\\mathbf{\\Omega}\\in\\mathbb{R}^{p\\times p}\n",
      "\\end{equation*}\n",
      "\n",
      "where $\\lambda_n$ is a tuning parameter.\n",
      "\n",
      "This minimization problem can be further decomposed into $p$ smaller problems, allowing us to recover the precision matrix in a column by column fashion (i.e. solving p optimization problems).\n",
      "\n",
      "$$\n",
      "\\hat{\\omega}_i=\\arg_\\omega\\min | \\mathbf{\\omega} |_1\\text{ subject to }|\\mathbf{\\Sigma}_n\\mathbf{\\omega}-\\textbf{e}_i|_\\infty\\le\\lambda_n\\text{, }\\mathbf{\\omega}\\in\\mathbb{R}^{p}\\text{            }(*)\n",
      "$$\n",
      "\n",
      "where $\\textbf{e}_i$ is the standard basis vector.\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Pseudocode"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\textbf{1.}$ If input x !symmetric: $\\Sigma_n = Corr(x)$\n",
      "\n",
      "$\\textbf{2.}$ Initialize $\\lambda_{min}$ and path length size. \n",
      "\n",
      "$\\textbf{3.}$ For $1\\le i\\le p\\text{ columns}$:\n",
      "\n",
      "$\\textbf{4.}$ Run parametric simplex method (available in C code) to solve the reformulated linear programming problem in $(*)$: \n",
      "    \n",
      "   $$\\hat{\\omega}_i^1\\leftarrow\\arg_{{\\omega}_i}\\min (\\mathbf{\\omega^{+}-\\omega^{-}}) \\text{ subject to  } \\left( \\begin{array}{cc}\n",
      "\\Sigma_n & -\\Sigma_n \\\\\n",
      "-\\Sigma_n & \\Sigma_n \\end{array} \\right) \n",
      "\\left( \\begin{array}{c}\n",
      "\\omega^+\\\\\n",
      "\\omega^-\\end{array} \\right)\\le\\left( \\begin{array}{c}\n",
      "\\lambda+e_i\\\\\n",
      "\\lambda-e_i\\end{array} \\right)$$\n",
      "\n",
      "  where $\\omega=\\omega^{+}-\\omega^-$ and $\\|\\omega\\|_1=\\omega^{+}+\\omega^-$, $\\omega^{+}\\ge 0, \\omega^{-}\\ge 0$\n",
      "\n",
      "$$\\textbf{OR}$$\n",
      "\n",
      "$\\textbf{4.}$ Prior to the for loop, perturb the feasible set (i.e. the constraining set) with a small positive constant $\\rho$ (e.g. $\\rho=\\sqrt{log(p/n)}$): $\\mathbf{\\Sigma}_{n,p}=\\mathbf{\\Sigma}_n+\\rho\\textbf{I}$. Then within for loop run primal dual interior-point method (RegLPInteriorPointSolver in NLPy module) to solve the reformulated linear programming problem in $(*)$:\n",
      "    \n",
      "\\begin{equation*}\n",
      "\\begin{split}\n",
      "\\hat{\\omega}_i^1 \\leftarrow \\arg_{{\\omega}_i}\\min&\\sum_{j=1}^{p}u_j\\text{ subject to:}\n",
      "\\\\\n",
      "&-\\omega_j\\le u_j\\textbf{ }\\forall\\textbf{ }1\\le j\\le p,\n",
      "\\\\\n",
      "&+\\omega_j\\le u_j\\textbf{ }\\forall\\textbf{ }1\\le j\\le p,\n",
      "\\\\\n",
      "&-\\hat{\\sigma}_k^T\\omega+I\\{k=i\\}\\le\\lambda_n{ }\\forall\\textbf{ }1\\le k\\le p,\n",
      "\\\\\n",
      "&+\\hat{\\sigma}_k^T\\omega-I\\{k=i\\}\\le\\lambda_n{ }\\forall\\textbf{ }1\\le k\\le p\n",
      "\\end{split}\n",
      "\\end{equation*}\n",
      "\n",
      "where $\\Sigma_n=(\\hat{\\sigma}_1,...,\\hat{\\sigma}_p)$.\n",
      "\n",
      "\n",
      "$\\textbf{5.}$ Symmetrize $\\hat{\\Omega}=(\\hat{\\omega}_{ij})=(\\hat{\\omega}_{ji})\\leftarrow\\omega^1_{ij}I\\{|\\hat{\\omega}_{ij}^1|\\le|\\hat{\\omega}_{ji}^1|\\}+\\omega^1_{ji}I\\{|\\hat{\\omega}_{ij}^1|\\gt|\\hat{\\omega}_{ji}^1|\\}$\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##CAPME"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Consider the following regression model with covariates:\n",
      "   \n",
      "$$\n",
      "\\textbf{y}=\\Gamma_0\\textbf{x}+\\textbf{z}\n",
      "$$\n",
      "\n",
      "where $\\textbf{y}=(y_1,...,y_p)^T$ is a random vector of responses,  $\\textbf{x}=(x_1,...,x_q)^T$ is a random vector of covariates or features, $\\Gamma_0$ is an unknown $p\\times q$ coefficient matrix, $\\textbf{z}$ is a $p\\times 1$ normal random vector with mean zero, covariance $\\Sigma_0\\in\\mathbb{R}^{p\\times p}$ and precision matrix $\\Omega_0=\\Sigma_0^{-1}$. Assume $\\textbf{x}$ and $\\textbf{z}$ are independent and that we have $n$ $iid$ observations $(\\textbf{x}_k,\\textbf{y}_k)$, ($k=1,...,n$) for the model.\n",
      "\n",
      "Using $\\mathcal{l}_1$ regularization (e.g. LASSO), we first estimate the coefficient matrix $\\Gamma_0$. Then we estimate $\\Omega_0$ using CLIME above. Like before, we can estimate both $\\Gamma_0$ and $\\Omega_0$ by performing the optimization on each column separately."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Pseudocode"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "$\\textbf{1.}$ Center and scale each column of $\\textbf{x}$ by its RMS. Center each column of $\\textbf{y}$ by its mean.\n",
      "\n",
      "$\\textbf{2.}$ Compute the sample covariances $S_{xy}$ and $S_{xx}$. \n",
      "\n",
      "$\\textbf{3.}$ For $1\\le i\\le p\\text{ columns}$\n",
      "\n",
      "Estimate\n",
      "\n",
      "$$\n",
      "\\hat{\\gamma}_i\\leftarrow\\arg_{\\gamma_i}\\min |\\gamma_i|_1\\text{ subject to }|S_{xy}-\\gamma_i^T S_{xx}|_\\infty \\le \\lambda_n,\\text{ }1\\le j\\le q\\text{ }(*)\n",
      "$$ \n",
      "    \n",
      "$\\text{where }\\hat{\\Gamma}=(\\hat{\\gamma}_1,...,\\hat{\\gamma}_p)$ \n",
      "    \n",
      "$\\text{This can be solved using a first-order conic solver (available in C and python at \n",
      "https://github.com/cvxgrp/scs)}$\n",
      "\n",
      "$\\textbf{4.}$ Substitute the estimated $\\hat{\\Gamma}$ in $(*)$ and compute the sample covariance, $S_{yy}$, substituting the column means with $\\hat{\\Gamma} x_k$, $1\\le k\\le p$.\n",
      "\n",
      "\n",
      "$\\textbf{5.}$ The optimization problem for estimating $\\omega^1_i$ for each of the $p$ columns is then:\n",
      "\n",
      "$$\n",
      "\\omega^1_i\\leftarrow\\min|\\omega_i|_1\\text{ subject to } |e_i - S_{yy}\\omega_i|_\\infty\\le \\tau_n\\text{ where }\\tau_n\\text{ is a tuning parameter.}\n",
      "$$  \n",
      "\n",
      "This can be solved using parametric simplex or primal dual interior point methods as in CLIME above.\n",
      " \n",
      "$\\textbf{6.}$ Symmetrize the final estimator as in step 5 in the CLIME algorithm."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Unit tests"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I enumerate the following tests needed to optimize this code.\n",
      "\n",
      "1. Check that input is a matrix. If not coerce to a matrix.\n",
      "2. Check that matrix input is positive semidefinite. If not, then coerce matrix by perturbing by a small quantity or treat sample covariance matrix as input.\n",
      "3. For CAPME, check the dimensionality of y and x and if their first dimensions are similar.\n",
      "4. For CAPME, remove missing data.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}